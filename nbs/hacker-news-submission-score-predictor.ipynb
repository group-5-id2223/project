{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"7dc0d9be1d31ece641148d1afb09bd03dd6651e1"},"source":["# Hacker News Submission Score Predictor w/ Keras and TensorFlow\n","\n","by Max Woolf ([@minimaxir](https://minimaxir.com))"]},{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"93ba18402e731c4293323a0aeb307d1109b53b0b","collapsed":true,"scrolled":true,"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import hopsworks\n","import torch\n","import torchtext\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"3500e7029ecde96fc6decfb602be4a5298641eae","collapsed":true,"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>url</th>\n","      <th>score</th>\n","      <th>time</th>\n","      <th>descendants</th>\n","      <th>by</th>\n","      <th>karma</th>\n","      <th>domain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12680033.0</td>\n","      <td>Medical school can be brutal, and it’s making ...</td>\n","      <td>https://www.washingtonpost.com/national/health...</td>\n","      <td>113.0</td>\n","      <td>1.476136e+09</td>\n","      <td>165.0</td>\n","      <td>snake117</td>\n","      <td>2750.0</td>\n","      <td>www.washingtonpost.com</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7787848.0</td>\n","      <td>A new way to buy seeds for your garden</td>\n","      <td>http://www.MySeedz.com</td>\n","      <td>1.0</td>\n","      <td>1.400816e+09</td>\n","      <td>0.0</td>\n","      <td>MySeedz</td>\n","      <td>1.0</td>\n","      <td>www.MySeedz.com</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12740841.0</td>\n","      <td>Facebook's 100 GbE Wedge Switch Makes Strides</td>\n","      <td>http://www.networkcomputing.com/data-centers/f...</td>\n","      <td>2.0</td>\n","      <td>1.476848e+09</td>\n","      <td>0.0</td>\n","      <td>kungfudoi</td>\n","      <td>14163.0</td>\n","      <td>www.networkcomputing.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1261361.0</td>\n","      <td>Iron Man 2</td>\n","      <td>http://www.imax.com/movie/ironman2</td>\n","      <td>1.0</td>\n","      <td>1.271145e+09</td>\n","      <td>-1.0</td>\n","      <td>Ladarius11</td>\n","      <td>2.0</td>\n","      <td>www.imax.com</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19007270.0</td>\n","      <td>Mark Zuckerberg, Let Me Be Your Ghost Writer</td>\n","      <td>https://www.nytimes.com/2019/01/25/opinion/mar...</td>\n","      <td>1.0</td>\n","      <td>1.548524e+09</td>\n","      <td>0.0</td>\n","      <td>theBashShell</td>\n","      <td>9917.0</td>\n","      <td>www.nytimes.com</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10240614.0</td>\n","      <td>Is Big Tech Too Powerful? Ask Google</td>\n","      <td>http://www.nytimes.com/2015/09/20/opinion/is-b...</td>\n","      <td>3.0</td>\n","      <td>1.442597e+09</td>\n","      <td>0.0</td>\n","      <td>Amorymeltzer</td>\n","      <td>18668.0</td>\n","      <td>www.nytimes.com</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>222098.0</td>\n","      <td>Bedsteads,soft and home furninshings from Dunelm</td>\n","      <td>http://www.dunelm-mill.com/category/Beds%5FBed...</td>\n","      <td>1.0</td>\n","      <td>1.213905e+09</td>\n","      <td>-1.0</td>\n","      <td>bedsteads</td>\n","      <td>1.0</td>\n","      <td>www.dunelm-mill.com</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1611421.0</td>\n","      <td>The quest for the next Journeyman Programming ...</td>\n","      <td>http://kirkwylie.blogspot.com/2010/08/i-want-n...</td>\n","      <td>3.0</td>\n","      <td>1.282060e+09</td>\n","      <td>2.0</td>\n","      <td>KirkWylie</td>\n","      <td>111.0</td>\n","      <td>kirkwylie.blogspot.com</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>265114.0</td>\n","      <td>Feedback on Q&amp;A apps in FB</td>\n","      <td>http://www.facebook.com/add.php?api_key=7712d2...</td>\n","      <td>1.0</td>\n","      <td>1.217701e+09</td>\n","      <td>0.0</td>\n","      <td>whleung</td>\n","      <td>1.0</td>\n","      <td>www.facebook.com</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>12080269.0</td>\n","      <td>A Proposal For the Dartmouth Summer Research P...</td>\n","      <td>http://www-formal.stanford.edu/jmc/history/dar...</td>\n","      <td>124.0</td>\n","      <td>1.468340e+09</td>\n","      <td>47.0</td>\n","      <td>projectramo</td>\n","      <td>4048.0</td>\n","      <td>www-formal.stanford.edu</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           id                                              title  \\\n","0  12680033.0  Medical school can be brutal, and it’s making ...   \n","1   7787848.0             A new way to buy seeds for your garden   \n","2  12740841.0      Facebook's 100 GbE Wedge Switch Makes Strides   \n","3   1261361.0                                         Iron Man 2   \n","4  19007270.0       Mark Zuckerberg, Let Me Be Your Ghost Writer   \n","5  10240614.0               Is Big Tech Too Powerful? Ask Google   \n","6    222098.0   Bedsteads,soft and home furninshings from Dunelm   \n","7   1611421.0  The quest for the next Journeyman Programming ...   \n","8    265114.0                         Feedback on Q&A apps in FB   \n","9  12080269.0  A Proposal For the Dartmouth Summer Research P...   \n","\n","                                                 url  score          time  \\\n","0  https://www.washingtonpost.com/national/health...  113.0  1.476136e+09   \n","1                             http://www.MySeedz.com    1.0  1.400816e+09   \n","2  http://www.networkcomputing.com/data-centers/f...    2.0  1.476848e+09   \n","3                 http://www.imax.com/movie/ironman2    1.0  1.271145e+09   \n","4  https://www.nytimes.com/2019/01/25/opinion/mar...    1.0  1.548524e+09   \n","5  http://www.nytimes.com/2015/09/20/opinion/is-b...    3.0  1.442597e+09   \n","6  http://www.dunelm-mill.com/category/Beds%5FBed...    1.0  1.213905e+09   \n","7  http://kirkwylie.blogspot.com/2010/08/i-want-n...    3.0  1.282060e+09   \n","8  http://www.facebook.com/add.php?api_key=7712d2...    1.0  1.217701e+09   \n","9  http://www-formal.stanford.edu/jmc/history/dar...  124.0  1.468340e+09   \n","\n","   descendants            by    karma                    domain  \n","0        165.0      snake117   2750.0    www.washingtonpost.com  \n","1          0.0       MySeedz      1.0           www.MySeedz.com  \n","2          0.0     kungfudoi  14163.0  www.networkcomputing.com  \n","3         -1.0    Ladarius11      2.0              www.imax.com  \n","4          0.0  theBashShell   9917.0           www.nytimes.com  \n","5          0.0  Amorymeltzer  18668.0           www.nytimes.com  \n","6         -1.0     bedsteads      1.0       www.dunelm-mill.com  \n","7          2.0     KirkWylie    111.0    kirkwylie.blogspot.com  \n","8          0.0       whleung      1.0          www.facebook.com  \n","9         47.0   projectramo   4048.0   www-formal.stanford.edu  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# project = hopsworks.login(project='id2223_enric')\n","# fs = project.get_feature_store()\n","# hackernews_fg = fs.get_feature_group(\"hackernews_fg\", 2)\n","# query = hackernews_fg.select_all()\n","# feature_view = fs.get_or_create_feature_view(name=\"hackernews_fv\",\n","#                                   version=2,\n","#                                   description=\"Hackernews feature view\",\n","#                                   labels=[\"score\"],\n","#                                   query=query)\n","from sklearn.model_selection import train_test_split\n","from urllib.parse import urlparse\n","\n","def url_to_domain(url):\n","    parsed_url = urlparse(url)\n","\n","    domain = parsed_url.netloc\n","    return domain\n","\n","feature_view = pd.read_csv('../feature_pipeline/pd_combined.csv')\n","\n","train_df, test_df = train_test_split(feature_view, test_size=0.05)\n","\n","df = train_df.sample(frac=1, random_state=123).dropna().reset_index(drop=True)\n","df['domain'] = df['url'].apply(url_to_domain)\n","\n","df.head(10)"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"644a5e101b25edf934fe33b672ec633c1e398336","collapsed":true,"trusted":true},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import Vocab\n","\n","def pad_sequences(seq, max_len=15):\n","    seq =  torch.tensor(seq)\n","    seq = nn.ConstantPad1d((0, max_len - len(seq)), 0)(seq)\n","    return seq\n","\n","tokenizer = get_tokenizer(\"basic_english\")"]},{"cell_type":"code","execution_count":4,"metadata":{"_uuid":"b55daa311c443e0cf961a9d424b03e32baa10b9a","collapsed":true,"trusted":true},"outputs":[],"source":["from collections import Counter\n","from functools import partial\n","\n","counter = Counter()\n","for title in df['title']:\n","    counter.update(tokenizer(title))\n","vocab = Vocab(counter)\n","text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n","df['title'] = df['title'].apply(text_pipeline)\n","df['title'] = df['title'].apply(pad_sequences)"]},{"cell_type":"markdown","metadata":{"_uuid":"a924d7ba85067fa07cc35eba48c2cfe268bbcabb"},"source":["### Top Domains\n","\n","Identify the top *n* domains by count (in this case *n* = 100), then transform it to a *n*D vector for each post."]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"bba9a0d62b8a75da61bdc0bb521507107ef5516d","collapsed":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["domain\n","github.com           4756\n","medium.com           3462\n","www.youtube.com      2760\n","www.nytimes.com      2143\n","techcrunch.com       1567\n","                     ... \n","edition.cnn.com       105\n","www.cbsnews.com       103\n","www.usatoday.com      103\n","chrome.google.com     103\n","www.techdirt.com      103\n","Name: count, Length: 100, dtype: int64\n"]}],"source":["num_domains = 100\n","\n","domain_counts = df['domain'].value_counts()[0:num_domains]\n","\n","print(domain_counts)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["titles = torch.stack([title for title in df['title'].values])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array(['www.washingtonpost.com', 'www.MySeedz.com',\n","       'www.networkcomputing.com', ..., 'www.slate.com',\n","       'stackoverflow.com', 'www.techcrunch.com'], dtype='<U95')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df['domain'].values.astype(str)"]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"e8a2182d48e0af02c1db7f449ac0f8e8a7bccaad","collapsed":true,"trusted":true},"outputs":[{"data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import LabelBinarizer\n","\n","top_domains = np.array(domain_counts.index, dtype=object)\n","\n","domain_encoder = LabelBinarizer()\n","domain_encoder.fit(top_domains)\n","\n","domains = domain_encoder.transform(df['domain'].values.astype(str))\n","domains[0]"]},{"cell_type":"markdown","metadata":{"_uuid":"892f13419e923efb918132ebd14990038753e6a0"},"source":["### Day-of-Week and Hour\n","\n","Convert day-of-week to a 7D vector and hours to a 24D vector. Both pandas and keras have useful functions for this workflow."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def to_categorical(y, num_classes):\n","    \"\"\" 1-hot encodes a tensor \"\"\"\n","    return np.eye(num_classes, dtype='uint8')[y]"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"af8e27fe36ec1e49817158de677b4070e42e3a06","collapsed":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 0 0 1 0 0 0]\n"," [0 0 0 1 0 0 0]\n"," [0 0 0 1 0 0 0]\n"," [0 0 0 1 0 0 0]\n"," [0 0 0 1 0 0 0]]\n","[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"]}],"source":["# from keras.utils import to_categorical\n","\n","dayofweeks = to_categorical(pd.to_datetime(df['time']).dt.dayofweek, 7)\n","hours = to_categorical(pd.to_datetime(df['time']).dt.hour, 24)\n","\n","print(dayofweeks[0:5])\n","print(hours[0:5])"]},{"cell_type":"markdown","metadata":{"_uuid":"869b7d1dcc98e712eeef2b1e2b11acaee8effeb2"},"source":["## Sample Weights\n","\n","Weight `score=1` samples lower so model places a higher importance on atypical submissions."]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"e2e59af44823777b2636f991fb4e361cbb574689","collapsed":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.  0.5 1.  0.5 0.5]\n"]}],"source":["weights = np.where(df['score'].values == 1, 0.5, 1.0)\n","print(weights[0:5])"]},{"cell_type":"markdown","metadata":{"_uuid":"7ba7a108c4bf2b64bae171da853ab7ba3c512f58"},"source":["## Trend and Time on New\n","\n","Unused in final model, but kept here for reference."]},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"ff955f9b48377059ad8979ec5824afcc2c4661d4","collapsed":true,"trusted":true},"outputs":[{"data":{"text/plain":["array([[0.58101883],\n","       [0.44240484],\n","       [0.58232834],\n","       [0.20376753],\n","       [0.71423612]])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","trend_encoder = MinMaxScaler()\n","trends = trend_encoder.fit_transform(pd.to_datetime(df['time']).values.reshape(-1, 1))\n","trends[0:5]"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"b2b95eb166c862d0cf3ac0c783b61dd9ceb4530b","collapsed":true,"trusted":true},"outputs":[],"source":["# newtime_encoder = MinMaxScaler()\n","# newtimes = trend_encoder.fit_transform(df['time_on_new'].values.reshape(-1, 1))\n","# newtimes[0:5]"]},{"cell_type":"markdown","metadata":{"_uuid":"4f6ab55f12a1db42e88840a5184c63317f409747"},"source":["## Build the Model Prototype"]},{"cell_type":"markdown","metadata":{"_uuid":"ec736e93b7a073e8bf68f29b80ca63dbebe3a004"},"source":["Add R^2 as a performance metric: https://jmlb.github.io/ml/2017/03/20/CoeffDetermination_CustomMetric4Keras/"]},{"cell_type":"code","execution_count":15,"metadata":{"_uuid":"6baf595ec8a40471438fcaada96b7e3f8ebf6c7a","collapsed":true,"trusted":true},"outputs":[],"source":["# from keras import backend as K\n","epsilon = 1e-7\n","def r_2(y_true, y_pred):\n","    SS_res =  torch.sum(torch.square( y_true - y_pred )) \n","    SS_tot = torch.sum(torch.square( y_true - torch.mean(y_true) ) ) \n","    return ( 1 - SS_res/(SS_tot + epsilon) )"]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"bf8e5369a0124adc6d2b47748270608fc0a2bb85","collapsed":true,"trusted":true},"outputs":[],"source":["def hybrid_loss(y_true, y_pred):\n","    weight_mae = 0.1\n","    weight_msle = 1.\n","    weight_poisson = 0.1\n","    \n","    mae_loss = weight_mae * torch.mean(torch.abs(y_pred - y_true), axis=-1)\n","    \n","    first_log = torch.log(torch.clip(y_pred, 1, None) + 1.)\n","    second_log = torch.log(torch.clip(y_true, epsilon, None) + 1.)\n","    msle_loss = weight_msle * torch.mean(torch.square(first_log - second_log), axis=-1)\n","    \n","    poisson_loss = weight_poisson * torch.mean(y_pred - y_true * torch.log(y_pred + epsilon), axis=-1)\n","    return torch.mean(mae_loss + msle_loss + poisson_loss)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["domains = torch.tensor(domains)\n","dayofweeks = torch.tensor(dayofweeks)\n","hours = torch.tensor(hours)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([129814, 15]),\n"," torch.Size([129814, 100]),\n"," torch.Size([129814, 7]),\n"," torch.Size([129814, 24]))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["titles.shape, domains.shape, dayofweeks.shape, hours.shape"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_words=15, num_hidden_layers=5):\n","        super().__init__()\n","\n","        self.embedding_titles = nn.Embedding(31001, 50)\n","        self.spatial_dropout = nn.Dropout2d(0.2)\n","        self.rnn_titles = nn.LSTM(50, 128)\n","\n","        self.hidden_layers = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Linear(259, 259),\n","                nn.ReLU(),\n","                nn.BatchNorm1d(259),\n","                nn.Dropout(0.5)\n","            )\n","            for _ in range(num_hidden_layers)\n","        ])\n","\n","        self.output_layer = nn.Linear(259, 1)\n","\n","    def forward(self, input_titles, input_domains, input_dayofweeks, input_hours):\n","        embedding_titles = self.embedding_titles(input_titles)\n","        spatial_dropout = self.spatial_dropout(embedding_titles)\n","        rnn_titles, _ = self.rnn_titles(spatial_dropout.permute(1, 0, 2))\n","\n","        concat = torch.cat([rnn_titles[-1], input_domains, input_dayofweeks, input_hours], dim=1)\n","        for layer in self.hidden_layers:\n","            concat = layer(concat)\n","\n","        output = self.output_layer(concat)\n","        return output"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["import torch.optim as optim\n","model = Model()\n","batch_lr = 1e-3\n","num_epochs = 100\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","lr_scheduler = optim.lr_scheduler.LinearLR(optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","\n","batch_size = 12\n","total_len = titles.shape[0]\n","gt_scores = torch.tensor(df['score'].values)\n","for epoch in range(num_epochs):\n","    loss_per_batch = []\n","    for i in tqdm(range(0, total_len, batch_size)):\n","        X_title = titles[i:i+batch_size]\n","        X_domain = domains[i:i+batch_size]\n","        X_dayofweeks = dayofweeks[i:i+batch_size]\n","        X_hours = hours[i:i+batch_size]\n","        y_true = gt_scores[i:i+batch_size]\n","\n","        score = model(X_title, X_domain, X_dayofweeks, X_hours)\n","        \n","        optimizer.zero_grad()\n","        loss = hybrid_loss(score, y_true)\n","        loss.backward()\n","        loss_per_batch.append(loss.item())\n","        optimizer.step()\n","    \n","    print(f\"Epoch: {epoch}/{num_epochs} ; Training loss: {np.mean(loss_per_batch)}\")"]},{"cell_type":"markdown","metadata":{"_uuid":"50a50c2cdcfbfd4acd2c0d8755d9c1b17643fe46"},"source":["The model uses a linear learning rate decay to allow it to learn better once it starts converging.\n","\n","Note: in this Kaggle Notebook, the training times out after 33 epochs when committing, so I set it to 25 here. You should probably train for longer. (50+ epochs)"]},{"cell_type":"markdown","metadata":{"_uuid":"c74104921970cad33e1c2e81b19d595e8a8c1031"},"source":["## Check Predictions Against Validation Set\n","\n","Predicting against data that was not trained in the model: the model does this poorly. :("]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["model = torch.load('model_v2.pkl')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Connected. Call `.close()` to terminate connection gracefully.\n","\n","Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/223381\n"]}],"source":["import hopsworks\n","project = hopsworks.login()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["from hsml.schema import Schema\n","from hsml.model_schema import ModelSchema"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.int64, torch.int64, torch.uint8, torch.uint8)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["X1.dtype, X2.dtype, X3.dtype, X4.dtype"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_schema \u001b[38;5;241m=\u001b[39m \u001b[43mSchema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX4\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m output_schema \u001b[38;5;241m=\u001b[39m Schema(score)\n\u001b[1;32m      3\u001b[0m model_schema \u001b[38;5;241m=\u001b[39m ModelSchema(input_schema, output_schema)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/hsml/schema.py:50\u001b[0m, in \u001b[0;36mSchema.__init__\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mobject\u001b[39m: Optional[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m ):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# A tensor schema is either ndarray of a list containing name, type and shape dicts\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m entry \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mobject\u001b[39m])\n\u001b[1;32m     51\u001b[0m     ):\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tensor_to_schema(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39mtensors\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/hsml/schema.py:50\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mobject\u001b[39m: Optional[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m ):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# A tensor schema is either ndarray of a list containing name, type and shape dicts\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mobject\u001b[39m])\n\u001b[1;32m     51\u001b[0m     ):\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tensor_to_schema(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39mtensors\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:1061\u001b[0m, in \u001b[0;36mTensor.__contains__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1056\u001b[0m     element, (torch\u001b[38;5;241m.\u001b[39mTensor, Number, torch\u001b[38;5;241m.\u001b[39mSymInt, torch\u001b[38;5;241m.\u001b[39mSymFloat, torch\u001b[38;5;241m.\u001b[39mSymBool)\n\u001b[1;32m   1057\u001b[0m ):\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (element \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m-> 1061\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1063\u001b[0m )\n","\u001b[0;31mRuntimeError\u001b[0m: Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>."]}],"source":["input_schema = Schema([X1, X2, X3, X4])\n","output_schema = Schema(score)\n","model_schema = ModelSchema(input_schema, output_schema)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hknews_model = mr.python.create_model(\n","    name=\"knews_model\",\n","    version=2,\n","    model_schema=model_schema,\n","    description=\"hknews_model mark 1\"\n",")\n","model_dir = './model_dir/'\n","hknews_model.save(model_dir)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def prepare_for_pred(title, url, time):\n","    title = pad_sequences(text_pipeline(title)).unsqueeze(0)\n","    domain = torch.tensor(domain_encoder.transform(np.array([url_to_domain(url)]).astype(str)))\n","    dayofweek = torch.tensor(to_categorical(pd.to_datetime(time).dayofweek, 7)).unsqueeze(0)\n","    hour = torch.tensor(to_categorical(pd.to_datetime(time).hour, 24)).unsqueeze(0)\n","    return title, domain, dayofweek, hour"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["title = test_df['title'].iloc[55][0]\n","url = test_df['url'].iloc[55]\n","time = test_df['time'].iloc[55]"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["X1, X2, X3, X4 = prepare_for_pred(title, url, time)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([1, 15]),\n"," torch.Size([1, 100]),\n"," torch.Size([1, 7]),\n"," torch.Size([1, 24]))"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["X1.shape, X2.shape, X3.shape, X4.shape"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n"]}],"source":["model.eval()\n","score = model(X1, X2, X3, X4)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[4.1687]], grad_fn=<AddmmBackward0>)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["score"]},{"cell_type":"code","execution_count":152,"metadata":{"_uuid":"27cba50c64e5e9eda0e33b3530f297689cfef824","collapsed":true,"trusted":false},"outputs":[{"ename":"NameError","evalue":"name 'split_prop' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43msplit_prop\u001b[49m \u001b[38;5;241m*\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([titles[\u001b[38;5;241m-\u001b[39mval_size:],\n\u001b[1;32m      4\u001b[0m                              domains[\u001b[38;5;241m-\u001b[39mval_size:],\n\u001b[1;32m      5\u001b[0m                              dayofweeks[\u001b[38;5;241m-\u001b[39mval_size:],\n\u001b[1;32m      6\u001b[0m                              hours[\u001b[38;5;241m-\u001b[39mval_size:]])[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m predictions\n","\u001b[0;31mNameError\u001b[0m: name 'split_prop' is not defined"]}],"source":["val_size = int(split_prop * df.shape[0])\n","\n","predictions = model.predict([titles[-val_size:],\n","                             domains[-val_size:],\n","                             dayofweeks[-val_size:],\n","                             hours[-val_size:]])[:, 0]\n","\n","predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3f9a99a8de6d8b3df499490138d3da481695b36a","collapsed":true,"trusted":false},"outputs":[],"source":["df_preds = pd.concat([pd.Series(df['title'].values[-val_size:]),\n","                      pd.Series(df['score'].values[-val_size:]),\n","                      pd.Series(predictions)],\n","                     axis=1)\n","df_preds.columns = ['title', 'actual', 'predicted']\n","# df_preds.to_csv('hn_val.csv', index=False)\n","df_preds.head(50)"]},{"cell_type":"markdown","metadata":{"_uuid":"27aa9024134e3ed086a8eac8bc1caa1009a3c979"},"source":["## Check Predictions Against Training Set\n","\n","The model should be able to predict these better."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"eefea11fef620a0f239c843ec927cc5a20278aa3","collapsed":true,"scrolled":true,"trusted":false},"outputs":[],"source":["train_size = int((1-split_prop) * df.shape[0])\n","\n","predictions = model.predict([titles[:train_size],\n","                             domains[:train_size],\n","                             dayofweeks[:train_size],\n","                             hours[:train_size]])[:, 0]\n","\n","df_preds = pd.concat([pd.Series(df['title'].values[:train_size]),\n","                      pd.Series(df['score'].values[:train_size]),\n","                      pd.Series(predictions)],\n","                     axis=1)\n","df_preds.columns = ['title', 'actual', 'predicted']\n","# df_preds.to_csv('hn_train.csv', index=False)\n","df_preds.head(50)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":1}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = nn.Sequential(\n",
    "    nn.Linear(768, 360), \n",
    "    nn.ELU(),\n",
    "    nn.Linear(360, 124),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(124, 2),\n",
    "    # nn.ELU(),\n",
    "    # nn.Linear(128, 2)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = copy.deepcopy(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearray(arr_str):\n",
    "    arr_str = arr_str.strip(\"'\").replace('\\n', '').replace('[', '').replace(']', '').split()\n",
    "    numpy_array = np.array(arr_str, dtype=float)\n",
    "    return numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DfDataset(Dataset):\n",
    "    def __init__(self, df, col):\n",
    "        self.df = df\n",
    "        self.col = col\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        val = self.df[self.col].iloc[idx]\n",
    "        reg_lbl = self.df['score'].iloc[idx]\n",
    "        if reg_lbl <= 1:\n",
    "            cls_lbl = 0\n",
    "            reg_lbl = reg_lbl\n",
    "        else:\n",
    "            cls_lbl = 1\n",
    "            reg_lbl = reg_lbl / 2800\n",
    "        arr = rearray(val)\n",
    "        return arr, cls_lbl, reg_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv('../data/compiled.csv')\n",
    "df_c = df_c.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = df_c[:70000], df_c[70000:]\n",
    "train_title_df = train_df[['title', 'score']]\n",
    "val_title_df = val_df[['title', 'score']]\n",
    "\n",
    "train_url_df = train_df[['url', 'score']]\n",
    "val_url_df = val_df[['url', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = DfDataset(train_title_df, col='title'), DfDataset(val_title_df, col='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=32, \n",
    "                          num_workers=2, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32,\n",
    "                        num_workers=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "optimizer = optim.AdamW(model_1.parameters(), lr=1e-5)\n",
    "lr_scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, epochs=500, steps_per_epoch=len(train_loader))\n",
    "mse_loss = nn.MSELoss()\n",
    "bce_loss = nn.BCELoss()\n",
    "def loss_fn(output, Y):\n",
    "    cls_lbl, reg_lbl = Y[0], Y[1]\n",
    "    cls_op, reg_op = F.sigmoid(output[:, 0]), output[:, 1]\n",
    "    bce_l = bce_loss(cls_op, cls_lbl)\n",
    "    mse_l = mse_loss(reg_op * cls_lbl, reg_lbl *  cls_lbl)\n",
    "    return bce_l + mse_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/500\n",
      "Training loss: 0.6594508046205998 Validation Loss: 0.6570080648215053\n",
      "Epoch: 2/500\n",
      "Training loss: 0.6410306334441062 Validation Loss: 0.6589330164388346\n",
      "Epoch: 3/500\n",
      "Training loss: 0.6364170515014222 Validation Loss: 0.6572224629191926\n",
      "Epoch: 4/500\n",
      "Training loss: 0.6313526404841072 Validation Loss: 0.6481342680347614\n",
      "Epoch: 5/500\n",
      "Training loss: 0.6268800272856595 Validation Loss: 0.6489515794923131\n",
      "Epoch: 6/500\n",
      "Training loss: 0.621579896488399 Validation Loss: 0.6510958737268234\n",
      "Epoch: 7/500\n",
      "Training loss: 0.615714778956809 Validation Loss: 0.6453538011438169\n",
      "Epoch: 8/500\n",
      "Training loss: 0.6103444621103119 Validation Loss: 0.6436298140131247\n",
      "Epoch: 9/500\n",
      "Training loss: 0.6029729639644814 Validation Loss: 0.6457765114764435\n",
      "Epoch: 10/500\n",
      "Training loss: 0.5959663734493788 Validation Loss: 0.6515623577677023\n",
      "Epoch: 11/500\n",
      "Training loss: 0.5877935127431775 Validation Loss: 0.6546416356921577\n",
      "Epoch: 12/500\n",
      "Training loss: 0.5791902054489422 Validation Loss: 0.6603284573402649\n",
      "Epoch: 13/500\n",
      "Training loss: 0.5693908345219858 Validation Loss: 0.6673599134047572\n",
      "Epoch: 14/500\n",
      "Training loss: 0.5595850575395215 Validation Loss: 0.6992272438523107\n",
      "Epoch: 15/500\n",
      "Training loss: 0.5493096968182916 Validation Loss: 0.7000699631703167\n",
      "Epoch: 16/500\n",
      "Training loss: 0.5380738566491678 Validation Loss: 0.7072105173485729\n",
      "Epoch: 17/500\n",
      "Training loss: 0.5270541611874997 Validation Loss: 0.7137724042129212\n",
      "Epoch: 18/500\n",
      "Training loss: 0.5131189931436039 Validation Loss: 0.7343412525356768\n",
      "Epoch: 19/500\n",
      "Training loss: 0.5021073029970774 Validation Loss: 0.7505507842420389\n",
      "Epoch: 20/500\n",
      "Training loss: 0.48737667001089185 Validation Loss: 0.7679326203874887\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    tr_loss_per_batch = []\n",
    "    val_loss_per_batch = []\n",
    "    for sample in train_loader:\n",
    "        X, Y_cls, Y_reg = sample\n",
    "        X, Y_cls, Y_reg = X.to(torch.float32).to(device), Y_cls.to(torch.float32).to(device), Y_reg.to(torch.float32).to(device)\n",
    "        target = model_1(X)\n",
    "        loss = loss_fn(target, [Y_cls, Y_reg])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss_per_batch.append(loss.item())\n",
    "        lr_scheduler.step()\n",
    "    with torch.no_grad():\n",
    "        for sample in val_loader:\n",
    "            X, Y_cls, Y_reg = sample\n",
    "            X, Y_cls, Y_reg = X.to(torch.float32).to(device), Y_cls.to(torch.float32).to(device), Y_reg.to(torch.float32).to(device)\n",
    "            target = model_1(X)\n",
    "            loss = loss_fn(target, [Y_cls, Y_reg])\n",
    "            val_loss_per_batch.append(loss.item())\n",
    "            \n",
    "    print(f\"Epoch: {epoch+1}/{epochs}\")\n",
    "    print(f\"Training loss: {np.mean(tr_loss_per_batch)} Validation Loss: {np.mean(val_loss_per_batch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,   1,  49,   1,   1,   2,   7,   1,   2, 144,   3,   3,   2,   2,\n",
       "          3,   1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

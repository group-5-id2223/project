{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_palette('husl')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Multiple projects found. \n",
      "\n",
      "\t (1) jayeshv\n",
      "\t (2) id2223_enric\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/197783\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store(\"id2223_enric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>descendants</th>\n",
       "      <th>by</th>\n",
       "      <th>karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Y Combinator</td>\n",
       "      <td>http://ycombinator.com</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.160418e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>pg</td>\n",
       "      <td>157234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34175557</td>\n",
       "      <td>A Year of Essential Reading on the Current</td>\n",
       "      <td>https://www.criterion.com/current/posts/8024-a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.672336e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>cocacola1</td>\n",
       "      <td>3719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5402062</td>\n",
       "      <td>Show HN: Rollbar - reliable, fast, platform-ag...</td>\n",
       "      <td>https://rollbar.com</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.363712e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>brianr</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21996698</td>\n",
       "      <td>A World Without Pain</td>\n",
       "      <td>https://www.newyorker.com/magazine/2020/01/13/...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.578524e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>zootme</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35659418</td>\n",
       "      <td>Give roundworms some weed and they’ll get the ...</td>\n",
       "      <td>https://arstechnica.com/science/2023/04/give-a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.682108e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>PaulHoule</td>\n",
       "      <td>60158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139996</th>\n",
       "      <td>3675265</td>\n",
       "      <td>Google Rebrands 'Android Market', It is now 'G...</td>\n",
       "      <td>http://infworm.com/google-rebrands-android-mar...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.331124e+09</td>\n",
       "      <td>-1</td>\n",
       "      <td>ansrikanth</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139997</th>\n",
       "      <td>795716</td>\n",
       "      <td>Clenbuterol pills</td>\n",
       "      <td>http://www.fitandshape.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.251717e+09</td>\n",
       "      <td>-1</td>\n",
       "      <td>rangilsmith</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139998</th>\n",
       "      <td>22873968</td>\n",
       "      <td>Save Cost on Cloud</td>\n",
       "      <td>https://medium.com/opsdev/boost-up-infrastruct...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.586919e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>abhaykumar_</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139999</th>\n",
       "      <td>9956343</td>\n",
       "      <td>The ionosphere on Venus finally confirmed</td>\n",
       "      <td>http://serious-science.org/colors-of-transit-o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.438016e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>mariannadavt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140000</th>\n",
       "      <td>2894149</td>\n",
       "      <td>Samsung hires Android hacker Cyanogen ~ THN</td>\n",
       "      <td>http://www.thehackernews.com/2011/08/samsung-h...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.313557e+09</td>\n",
       "      <td>-1</td>\n",
       "      <td>unixroot</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140001 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "0              1                                       Y Combinator   \n",
       "1       34175557         A Year of Essential Reading on the Current   \n",
       "2        5402062  Show HN: Rollbar - reliable, fast, platform-ag...   \n",
       "3       21996698                               A World Without Pain   \n",
       "4       35659418  Give roundworms some weed and they’ll get the ...   \n",
       "...          ...                                                ...   \n",
       "139996   3675265  Google Rebrands 'Android Market', It is now 'G...   \n",
       "139997    795716                                  Clenbuterol pills   \n",
       "139998  22873968                                 Save Cost on Cloud   \n",
       "139999   9956343          The ionosphere on Venus finally confirmed   \n",
       "140000   2894149        Samsung hires Android hacker Cyanogen ~ THN   \n",
       "\n",
       "                                                      url  score  \\\n",
       "0                                  http://ycombinator.com   57.0   \n",
       "1       https://www.criterion.com/current/posts/8024-a...    1.0   \n",
       "2                                     https://rollbar.com    2.0   \n",
       "3       https://www.newyorker.com/magazine/2020/01/13/...    2.0   \n",
       "4       https://arstechnica.com/science/2023/04/give-a...    1.0   \n",
       "...                                                   ...    ...   \n",
       "139996  http://infworm.com/google-rebrands-android-mar...    1.0   \n",
       "139997                         http://www.fitandshape.com    1.0   \n",
       "139998  https://medium.com/opsdev/boost-up-infrastruct...    1.0   \n",
       "139999  http://serious-science.org/colors-of-transit-o...    1.0   \n",
       "140000  http://www.thehackernews.com/2011/08/samsung-h...    1.0   \n",
       "\n",
       "                time  descendants            by   karma  \n",
       "0       1.160418e+09           15            pg  157234  \n",
       "1       1.672336e+09            0     cocacola1    3719  \n",
       "2       1.363712e+09            3        brianr    1012  \n",
       "3       1.578524e+09            0        zootme      46  \n",
       "4       1.682108e+09            1     PaulHoule   60158  \n",
       "...              ...          ...           ...     ...  \n",
       "139996  1.331124e+09           -1    ansrikanth       4  \n",
       "139997  1.251717e+09           -1   rangilsmith       1  \n",
       "139998  1.586919e+09            0   abhaykumar_      10  \n",
       "139999  1.438016e+09            0  mariannadavt       2  \n",
       "140000  1.313557e+09           -1      unixroot     130  \n",
       "\n",
       "[140001 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hackernews_df = pd.read_csv(\"./pd_combined.csv\")\n",
    "hackernews_df['id'] = hackernews_df['id'].astype(float).astype(np.int32)\n",
    "hackernews_df['title'] = hackernews_df['title'].astype(str)\n",
    "hackernews_df['url'] = hackernews_df['url'].astype(str)\n",
    "hackernews_df['descendants'] = hackernews_df['descendants'].astype(float).astype(int)\n",
    "hackernews_df['by'] = hackernews_df['by'].astype(str)\n",
    "hackernews_df['karma'] = hackernews_df['karma'].astype(float).astype(int)\n",
    "hackernews_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140001 entries, 0 to 140000\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           140001 non-null  int64  \n",
      " 1   title        140001 non-null  object \n",
      " 2   url          136641 non-null  object \n",
      " 3   score        140001 non-null  float64\n",
      " 4   time         140001 non-null  float64\n",
      " 5   descendants  140001 non-null  float64\n",
      " 6   by           140001 non-null  object \n",
      " 7   karma        140001 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "hackernews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>descendants</th>\n",
       "      <th>karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.400010e+05</td>\n",
       "      <td>140001.000000</td>\n",
       "      <td>1.400010e+05</td>\n",
       "      <td>140001.000000</td>\n",
       "      <td>140001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.512220e+07</td>\n",
       "      <td>15.381719</td>\n",
       "      <td>1.475778e+09</td>\n",
       "      <td>7.404519</td>\n",
       "      <td>14030.578617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.110996e+07</td>\n",
       "      <td>60.624857</td>\n",
       "      <td>1.354500e+08</td>\n",
       "      <td>36.510983</td>\n",
       "      <td>30997.233701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.160418e+09</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.133854e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.359471e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.291785e+07</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.478754e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1648.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.364891e+07</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.593148e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.879956e+07</td>\n",
       "      <td>2873.000000</td>\n",
       "      <td>1.703803e+09</td>\n",
       "      <td>1449.000000</td>\n",
       "      <td>384399.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          score          time    descendants          karma\n",
       "count  1.400010e+05  140001.000000  1.400010e+05  140001.000000  140001.000000\n",
       "mean   1.512220e+07      15.381719  1.475778e+09       7.404519   14030.578617\n",
       "std    1.110996e+07      60.624857  1.354500e+08      36.510983   30997.233701\n",
       "min    1.000000e+00       0.000000  1.160418e+09      -1.000000     -54.000000\n",
       "25%    5.133854e+06       1.000000  1.359471e+09       0.000000     141.000000\n",
       "50%    1.291785e+07       2.000000  1.478754e+09       0.000000    1648.000000\n",
       "75%    2.364891e+07       4.000000  1.593148e+09       1.000000   11024.000000\n",
       "max    3.879956e+07    2873.000000  1.703803e+09    1449.000000  384399.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hackernews_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add everything into the feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FeatureGroupWarning: The provided time travel format `None` has been overwritten because Stream enabled feature groups only support `HUDI`\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/197783/featurestores/197702/featuregroups). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270089,\"usrMsg\":\"project: id2223_enric, featurestoreId: 197702\",\"errorMsg\":\"The feature group you are trying to create does already exist.\"}', error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: id2223_enric, featurestoreId: 197702",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m hackernews_fg \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mcreate_feature_group(\n\u001b[1;32m      2\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhackernews_fg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     primary_key\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m hackernews_fg\u001b[38;5;241m.\u001b[39minsert(hackernews_df)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/feature_group.py:1984\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[0;34m(self, features, overwrite, operation, storage, write_options, validation_options, save_code, wait)\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m write_options:\n\u001b[1;32m   1982\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait\n\u001b[0;32m-> 1984\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_group_engine\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1986\u001b[0m     feature_dataframe\u001b[38;5;241m=\u001b[39mfeature_dataframe,\n\u001b[1;32m   1987\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[1;32m   1988\u001b[0m     operation\u001b[38;5;241m=\u001b[39moperation,\n\u001b[1;32m   1989\u001b[0m     storage\u001b[38;5;241m=\u001b[39mstorage\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mif\u001b[39;00m storage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1990\u001b[0m     write_options\u001b[38;5;241m=\u001b[39mwrite_options,\n\u001b[1;32m   1991\u001b[0m     validation_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_report\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalidation_options},\n\u001b[1;32m   1992\u001b[0m )\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_code \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   1994\u001b[0m     ge_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ge_report\u001b[38;5;241m.\u001b[39mingestion_result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINGESTED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1995\u001b[0m ):\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_engine\u001b[38;5;241m.\u001b[39msave_code(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:91\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[0;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m dataframe_features \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mparse_schema_feature_group(\n\u001b[1;32m     86\u001b[0m     feature_dataframe, feature_group\u001b[38;5;241m.\u001b[39mtime_travel_format\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39m_id:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# only save metadata if feature group does not exist\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_feature_group_metadata(\n\u001b[1;32m     92\u001b[0m         feature_group, dataframe_features, write_options\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# else, just verify that feature group schema matches user-provided dataframe\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_schema_compatibility(\n\u001b[1;32m     97\u001b[0m         feature_group\u001b[38;5;241m.\u001b[39mfeatures, dataframe_features\n\u001b[1;32m     98\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:342\u001b[0m, in \u001b[0;36mFeatureGroupEngine.save_feature_group_metadata\u001b[0;34m(self, feature_group, dataframe_features, write_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m     _write_options \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    330\u001b[0m         [\n\u001b[1;32m    331\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: v}\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     )\n\u001b[1;32m    338\u001b[0m     feature_group\u001b[38;5;241m.\u001b[39m_deltastreamer_jobconf \u001b[38;5;241m=\u001b[39m DeltaStreamerJobConf(\n\u001b[1;32m    339\u001b[0m         _write_options, _spark_options\n\u001b[1;32m    340\u001b[0m     )\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_group_api\u001b[38;5;241m.\u001b[39msave(feature_group)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Group created successfully, explore it at \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_feature_group_url(feature_group)\n\u001b[1;32m    346\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_group_api.py:48\u001b[0m, in \u001b[0;36mFeatureGroupApi.save\u001b[0;34m(self, feature_group_instance)\u001b[0m\n\u001b[1;32m     39\u001b[0m path_params \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     _client\u001b[38;5;241m.\u001b[39m_project_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeaturegroups\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m ]\n\u001b[1;32m     46\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     47\u001b[0m feature_group_object \u001b[38;5;241m=\u001b[39m feature_group_instance\u001b[38;5;241m.\u001b[39mupdate_from_response_json(\n\u001b[0;32m---> 48\u001b[0m     _client\u001b[38;5;241m.\u001b[39m_send_request(\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m         path_params,\n\u001b[1;32m     51\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m     52\u001b[0m         data\u001b[38;5;241m=\u001b[39mfeature_group_instance\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[1;32m     53\u001b[0m     ),\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m feature_group_object\u001b[38;5;241m.\u001b[39mfeature_store \u001b[38;5;241m=\u001b[39m feature_group_instance\u001b[38;5;241m.\u001b[39mfeature_store\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_group_object\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(inst, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/client/base.py:179\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    176\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39msend(prepped, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/197783/featurestores/197702/featuregroups). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270089,\"usrMsg\":\"project: id2223_enric, featurestoreId: 197702\",\"errorMsg\":\"The feature group you are trying to create does already exist.\"}', error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: id2223_enric, featurestoreId: 197702"
     ]
    }
   ],
   "source": [
    "hackernews_fg = fs.create_feature_group(\n",
    "    name=\"hackernews_fg\",\n",
    "    version=1,\n",
    "    description=\"Hackernews feature group\",\n",
    "    time_travel_format=None,\n",
    "    online_enabled=True,\n",
    "    statistics_config={\"enabled\": True, \"histograms\": True, \"correlations\": True, \"exact_uniqueness\": True},\n",
    "    primary_key=[\"id\"],\n",
    ")\n",
    "hackernews_fg.insert(hackernews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/197783/featurestores/197702/featuregroups). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270089,\"usrMsg\":\"project: id2223_enric, featurestoreId: 197702\",\"errorMsg\":\"The feature group you are trying to create does already exist.\"}', error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: id2223_enric, featurestoreId: 197702",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hackernews_fg\u001b[38;5;241m.\u001b[39minsert(hackernews_df)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/feature_group.py:1984\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[0;34m(self, features, overwrite, operation, storage, write_options, validation_options, save_code, wait)\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m write_options:\n\u001b[1;32m   1982\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait\n\u001b[0;32m-> 1984\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_group_engine\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1986\u001b[0m     feature_dataframe\u001b[38;5;241m=\u001b[39mfeature_dataframe,\n\u001b[1;32m   1987\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[1;32m   1988\u001b[0m     operation\u001b[38;5;241m=\u001b[39moperation,\n\u001b[1;32m   1989\u001b[0m     storage\u001b[38;5;241m=\u001b[39mstorage\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mif\u001b[39;00m storage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1990\u001b[0m     write_options\u001b[38;5;241m=\u001b[39mwrite_options,\n\u001b[1;32m   1991\u001b[0m     validation_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_report\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalidation_options},\n\u001b[1;32m   1992\u001b[0m )\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_code \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   1994\u001b[0m     ge_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ge_report\u001b[38;5;241m.\u001b[39mingestion_result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINGESTED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1995\u001b[0m ):\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_engine\u001b[38;5;241m.\u001b[39msave_code(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:91\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[0;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m dataframe_features \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mparse_schema_feature_group(\n\u001b[1;32m     86\u001b[0m     feature_dataframe, feature_group\u001b[38;5;241m.\u001b[39mtime_travel_format\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39m_id:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# only save metadata if feature group does not exist\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_feature_group_metadata(\n\u001b[1;32m     92\u001b[0m         feature_group, dataframe_features, write_options\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# else, just verify that feature group schema matches user-provided dataframe\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_schema_compatibility(\n\u001b[1;32m     97\u001b[0m         feature_group\u001b[38;5;241m.\u001b[39mfeatures, dataframe_features\n\u001b[1;32m     98\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:342\u001b[0m, in \u001b[0;36mFeatureGroupEngine.save_feature_group_metadata\u001b[0;34m(self, feature_group, dataframe_features, write_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m     _write_options \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    330\u001b[0m         [\n\u001b[1;32m    331\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: v}\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     )\n\u001b[1;32m    338\u001b[0m     feature_group\u001b[38;5;241m.\u001b[39m_deltastreamer_jobconf \u001b[38;5;241m=\u001b[39m DeltaStreamerJobConf(\n\u001b[1;32m    339\u001b[0m         _write_options, _spark_options\n\u001b[1;32m    340\u001b[0m     )\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_group_api\u001b[38;5;241m.\u001b[39msave(feature_group)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Group created successfully, explore it at \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_feature_group_url(feature_group)\n\u001b[1;32m    346\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/core/feature_group_api.py:48\u001b[0m, in \u001b[0;36mFeatureGroupApi.save\u001b[0;34m(self, feature_group_instance)\u001b[0m\n\u001b[1;32m     39\u001b[0m path_params \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     _client\u001b[38;5;241m.\u001b[39m_project_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeaturegroups\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m ]\n\u001b[1;32m     46\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     47\u001b[0m feature_group_object \u001b[38;5;241m=\u001b[39m feature_group_instance\u001b[38;5;241m.\u001b[39mupdate_from_response_json(\n\u001b[0;32m---> 48\u001b[0m     _client\u001b[38;5;241m.\u001b[39m_send_request(\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m         path_params,\n\u001b[1;32m     51\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m     52\u001b[0m         data\u001b[38;5;241m=\u001b[39mfeature_group_instance\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[1;32m     53\u001b[0m     ),\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m feature_group_object\u001b[38;5;241m.\u001b[39mfeature_store \u001b[38;5;241m=\u001b[39m feature_group_instance\u001b[38;5;241m.\u001b[39mfeature_store\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_group_object\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(inst, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hsfs/client/base.py:179\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    176\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39msend(prepped, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/197783/featurestores/197702/featuregroups). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270089,\"usrMsg\":\"project: id2223_enric, featurestoreId: 197702\",\"errorMsg\":\"The feature group you are trying to create does already exist.\"}', error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: id2223_enric, featurestoreId: 197702"
     ]
    }
   ],
   "source": [
    "hackernews_fg = fs.get_feature_group(\"hackernews_fg\", 1)\n",
    "hackernews_fg.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
